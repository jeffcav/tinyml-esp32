{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP with floating point weights and baremetal C implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import serial\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import src.python.dataset.yalefaces as yalefaces\n",
    "import src.python.model.util as util\n",
    "\n",
    "np.random.seed(99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "### Load and normalize the raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = yalefaces.load(\"dataset/yalefaces\", flatten=True)\n",
    "X = X.astype(\"float32\") / 255.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compress dataset with PCA\n",
    "Computing PCA parameters from the whole dataset for educational purposes only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_faces, num_pixels = X.shape\n",
    "num_principal_components = int(num_faces)\n",
    "pca = PCA(n_components=num_principal_components)\n",
    "\n",
    "pca.fit(X)\n",
    "X = pca.transform(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True, stratify=y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert datasets to pythorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(torch.Tensor(X_train), torch.LongTensor(y_train))\n",
    "test_dataset = TensorDataset(torch.Tensor(X_test), torch.LongTensor(y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.layers = torch.nn.Sequential(\n",
    "      torch.nn.Linear(165, 96, bias=False),\n",
    "      torch.nn.ReLU(),\n",
    "      torch.nn.Linear(96, 15, bias=False),\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accs= []\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(200):\n",
    "    train_data = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "    error, num_samples = util.train(model, device, train_data, optimizer)\n",
    "    loss = float(error)/float(num_samples)\n",
    "    train_losses.append(loss)\n",
    "\n",
    "    acc = util.test(model, device, train_data)\n",
    "    train_accs.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 81.82\n"
     ]
    }
   ],
   "source": [
    "test_data = DataLoader(test_dataset, batch_size=len(test_dataset))\n",
    "acc = util.test(model, device, test_data)\n",
    "print(f\"Test accuracy: {acc * 100:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export model weights as C code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params=model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_indexes = [0, 2]\n",
    "\n",
    "src_filename = 'src/embedded/1-mlp-baremetal-float/esp32s3/main/mlp_weights.c'\n",
    "hdr_filename = 'src/embedded/1-mlp-baremetal-float/esp32s3/include/mlp_weights.h'\n",
    "\n",
    "with open(src_filename, 'w') as source, open(hdr_filename, 'w') as header:\n",
    "    \n",
    "    header.write('#ifndef MLP_WEIGHTS\\n#define MLP_WEIGHTS\\n\\n')\n",
    "    header.write('#include <stdint.h>\\n\\n')\n",
    "    \n",
    "    source.write('#include \"mlp_weights.h\"\\n\\n')\n",
    "\n",
    "    for layer in layer_indexes:\n",
    "        weights = util.get_weights(model_params, layer).flatten()\n",
    "\n",
    "        # Weights\n",
    "        header.write(f\"extern const float layer_{layer}_weights[{len(weights)}];\\n\")\n",
    "        source.write(f\"const float layer_{layer}_weights[{len(weights)}] = {{\")\n",
    "        for i in range(len(weights)-1):\n",
    "            source.write(f\"{weights[i]}, \")\n",
    "        source.write(f\"{weights[len(weights)-1]}}};\\n\\n\")\n",
    "\n",
    "    header.write('\\n#endif // end of MLP_PARAMS\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Talk to an ESP32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 81.82%, Average Inference Duration = 4.545ms: 100%|██████████| 33/33 [00:02<00:00, 14.08it/s]\n"
     ]
    }
   ],
   "source": [
    "CPU_FREQ_KHZ = 240000\n",
    "num_tests = len(X_test)\n",
    "\n",
    "with serial.Serial(\"/dev/ttyUSB0\", 115200, timeout=None) as esp32, tqdm(total=num_tests, file=sys.stdout) as pbar:\n",
    "    esp32.read_until(b'Ready\\n')\n",
    "\n",
    "    num_correct = 0\n",
    "    all_elapsed = []\n",
    "\n",
    "    for i in range(num_tests):\n",
    "        face = X_test[i]\n",
    "        expected = y_test[i]\n",
    "\n",
    "        # check if device is ready\n",
    "        msg = esp32.read(18)\n",
    "        assert msg == b'Waiting for input\\n', msg\n",
    "\n",
    "        # send command=1 (new inference)\n",
    "        esp32.write(b'\\x01')\n",
    "\n",
    "        # send input (165 bytes)\n",
    "        esp32.write(face.tobytes())\n",
    "\n",
    "        # read output\n",
    "        subject = esp32.read(4)\n",
    "        subject = int.from_bytes(subject, byteorder=\"little\")\n",
    "\n",
    "        # read inference duration\n",
    "        elapsed = esp32.read(4)\n",
    "        elapsed = int.from_bytes(elapsed, byteorder=\"little\")\n",
    "        all_elapsed.append(elapsed)\n",
    "\n",
    "        # count correct inferences\n",
    "        if expected == subject:\n",
    "            num_correct += 1\n",
    "\n",
    "        # update progress bar\n",
    "        acc = num_correct/(i+1)\n",
    "        pbar.set_description(f\"Accuracy = {acc*100:.2f}%, Average Inference Duration = {elapsed/CPU_FREQ_KHZ:.3f}ms\")\n",
    "        pbar.update(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "335bc577f4714844361dc0df4b7a2ea152f61cb4ad8245b2534b0c0899fbb0f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
